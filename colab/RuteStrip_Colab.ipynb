{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”ï¸ Sistem Rekomendasi Rute Pendakian Gunung\n",
        "## Content-Based Filtering dengan SBERT dan Cosine Similarity\n",
        "\n",
        "**Paper:** \"Sistem Rekomendasi Rute Pendakian Gunung Menggunakan Content-Based Filtering Berbasis SBERT dan Cosine Similarity\"\n",
        "\n",
        "---\n",
        "\n",
        "### Komponen Utama:\n",
        "1. **Data Collection & Fusion**: Ekstraksi fitur dari GPX + deskripsi manual\n",
        "2. **Preprocessing**: Regex cleaning, case folding, stopword removal (selektif)\n",
        "3. **Feature Extraction**: SBERT (paraphrase-multilingual-MiniLM-L12-v2) â†’ 384 dimensi\n",
        "4. **Similarity & Ranking**: Cosine Similarity dengan Top-N ranking"
      ],
      "metadata": {
        "id": "title-cell"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-deps"
      },
      "outputs": [],
      "source": [
        "#@title 1ï¸âƒ£ Install Dependencies\n",
        "!pip install gpxpy sentence-transformers scikit-learn pandas numpy -q\n",
        "print(\"âœ… Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2ï¸âƒ£ Import Libraries\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gpxpy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Libraries imported!\")"
      ],
      "metadata": {
        "id": "import-libs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3ï¸âƒ£ Text Preprocessing (Sesuai Paper)\n",
        "\n",
        "STOPWORDS_ID = {\n",
        "    'yang', 'dan', 'di', 'ke', 'dari', 'ini', 'itu', 'dengan', 'untuk', 'pada',\n",
        "    'adalah', 'sebagai', 'dalam', 'juga', 'atau', 'ada', 'oleh', 'akan', 'sudah',\n",
        "    'saya', 'kami', 'kita', 'mereka', 'dia', 'ia', 'anda', 'tersebut', 'dapat',\n",
        "    'bisa', 'harus', 'telah', 'lalu', 'kemudian', 'serta', 'maupun', 'saat',\n",
        "    'ketika', 'bila', 'kalau', 'jika', 'karena', 'agar', 'supaya', 'hingga',\n",
        "    'sampai', 'antara', 'seperti', 'yaitu', 'yakni', 'bahwa', 'namun', 'tetapi'\n",
        "}\n",
        "\n",
        "PRESERVE_WORDS = {\n",
        "    'tidak', 'bukan', 'jangan', 'belum', 'tanpa',\n",
        "    'mudah', 'sulit', 'curam', 'landai', 'panjang', 'pendek',\n",
        "    'tinggi', 'rendah', 'sejuk', 'panas', 'dingin', 'indah', 'bagus',\n",
        "    'pemula', 'berpengalaman', 'santai', 'menantang', 'ekstrem'\n",
        "}\n",
        "\n",
        "def preprocess_text(text, remove_stopwords=True):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s\\-]', ' ', text)\n",
        "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = text.lower()\n",
        "    if remove_stopwords:\n",
        "        words = text.split()\n",
        "        filtered_words = [w for w in words if w in PRESERVE_WORDS or w not in STOPWORDS_ID]\n",
        "        text = ' '.join(filtered_words)\n",
        "    return text\n",
        "\n",
        "print(\"âœ… Preprocessing functions defined!\")"
      ],
      "metadata": {
        "id": "preprocessing"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4ï¸âƒ£ GPX Processing Functions\n",
        "\n",
        "def parse_gpx(gpx_path):\n",
        "    with open(gpx_path, 'r', encoding='utf-8') as gpx_file:\n",
        "        gpx = gpxpy.parse(gpx_file)\n",
        "    points = []\n",
        "    for track in gpx.tracks:\n",
        "        for segment in track.segments:\n",
        "            for point in segment.points:\n",
        "                points.append({\n",
        "                    'lat': point.latitude,\n",
        "                    'lon': point.longitude,\n",
        "                    'ele': point.elevation if point.elevation else 0\n",
        "                })\n",
        "    return gpx, points\n",
        "\n",
        "def calculate_statistics(gpx, points):\n",
        "    distance_km = gpx.length_3d() / 1000.0\n",
        "    elevation_gain = sum(max(0, points[i]['ele'] - points[i-1]['ele']) for i in range(1, len(points)))\n",
        "    naismith_duration = (distance_km / 5) + (elevation_gain / 600)\n",
        "    average_grade = (elevation_gain / (distance_km * 1000)) * 100 if distance_km > 0 else 0\n",
        "    \n",
        "    if average_grade < 5: difficulty = \"mudah\"\n",
        "    elif average_grade < 10: difficulty = \"sedang\"\n",
        "    elif average_grade < 15: difficulty = \"sulit\"\n",
        "    else: difficulty = \"sangat sulit\"\n",
        "    \n",
        "    elevations = [p['ele'] for p in points if p['ele'] > 0]\n",
        "    return {\n",
        "        'distance_km': round(distance_km, 2),\n",
        "        'elevation_gain_m': int(elevation_gain),\n",
        "        'naismith_duration_hour': round(naismith_duration, 2),\n",
        "        'average_grade_pct': round(average_grade, 2),\n",
        "        'min_elevation': int(min(elevations)) if elevations else 0,\n",
        "        'max_elevation': int(max(elevations)) if elevations else 0,\n",
        "        'difficulty': difficulty\n",
        "    }\n",
        "\n",
        "def generate_narrative(stats, manual_description=\"\"):\n",
        "    jarak_desc = \"pendek\" if stats['distance_km'] < 3 else \"sedang\" if stats['distance_km'] < 7 else \"panjang\"\n",
        "    waktu_desc = \"singkat\" if stats['naismith_duration_hour'] < 2 else \"sedang\" if stats['naismith_duration_hour'] < 4 else \"lama\"\n",
        "    \n",
        "    if stats['average_grade_pct'] < 5: grade_desc = \"landai dan ramah pemula\"\n",
        "    elif stats['average_grade_pct'] < 10: grade_desc = \"menantang dengan kemiringan sedang\"\n",
        "    elif stats['average_grade_pct'] < 15: grade_desc = \"curam dan membutuhkan stamina yang baik\"\n",
        "    else: grade_desc = \"sangat curam dan berbahaya\"\n",
        "    \n",
        "    narrative = f\"Jalur pendakian dengan jarak {jarak_desc} sekitar {stats['distance_km']} kilometer. Estimasi waktu tempuh {waktu_desc} selama {stats['naismith_duration_hour']} jam. Karakteristik jalur {grade_desc} dengan grade rata-rata {stats['average_grade_pct']}%. Total kenaikan elevasi {stats['elevation_gain_m']} meter. Tingkat kesulitan: {stats['difficulty']}.\"\n",
        "    \n",
        "    if manual_description:\n",
        "        narrative = manual_description + \" \" + narrative\n",
        "    return narrative\n",
        "\n",
        "print(\"âœ… GPX processing functions defined!\")"
      ],
      "metadata": {
        "id": "gpx-functions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5ï¸âƒ£ Load SBERT Model\n",
        "print(\"â³ Loading SBERT model...\")\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "print(f\"âœ… Model loaded! Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
      ],
      "metadata": {
        "id": "load-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6ï¸âƒ£ Core Functions\n",
        "\n",
        "routes_database = []\n",
        "\n",
        "def generate_embedding(text):\n",
        "    return model.encode(text).tolist()\n",
        "\n",
        "def calc_similarity(query_emb, route_emb):\n",
        "    return float(cosine_similarity(\n",
        "        np.array(query_emb).reshape(1, -1),\n",
        "        np.array(route_emb).reshape(1, -1)\n",
        "    )[0][0])\n",
        "\n",
        "def add_route(name, gpx_path, manual_description=\"\"):\n",
        "    try:\n",
        "        gpx, points = parse_gpx(gpx_path)\n",
        "        if not points: return None\n",
        "        stats = calculate_statistics(gpx, points)\n",
        "        narrative = generate_narrative(stats, manual_description)\n",
        "        embedding = generate_embedding(preprocess_text(narrative, False))\n",
        "        route = {\n",
        "            'id': len(routes_database) + 1,\n",
        "            'name': name,\n",
        "            'stats': stats,\n",
        "            'narrative_text': narrative,\n",
        "            'embedding': embedding\n",
        "        }\n",
        "        routes_database.append(route)\n",
        "        print(f\"âœ… Added: {name} | {stats['distance_km']}km | {stats['difficulty']}\")\n",
        "        return route\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def search_routes(query, top_n=5):\n",
        "    if not routes_database: return []\n",
        "    processed = preprocess_text(query, True)\n",
        "    query_emb = generate_embedding(processed)\n",
        "    results = [{'route': r, 'similarity': calc_similarity(query_emb, r['embedding'])} for r in routes_database]\n",
        "    results.sort(key=lambda x: x['similarity'], reverse=True)\n",
        "    return results[:top_n]\n",
        "\n",
        "print(\"âœ… Core functions defined!\")"
      ],
      "metadata": {
        "id": "core-functions"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7ï¸âƒ£ Upload GPX Files\n",
        "print(\"ðŸ“ Upload file GPX Anda:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith(('.gpx', '.xml')):\n",
        "        name = filename.replace('.gpx', '').replace('.xml', '').replace('_', ' ').title()\n",
        "        desc = input(f\"Deskripsi untuk {name} (Enter untuk skip): \")\n",
        "        add_route(name, filename, desc)\n",
        "\n",
        "print(f\"\\nðŸ“š Total: {len(routes_database)} rute\")"
      ],
      "metadata": {
        "id": "upload-gpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8ï¸âƒ£ Demo dengan Data Sample (jika tidak upload GPX)\n",
        "if not routes_database:\n",
        "    samples = [\n",
        "        ('Gunung Prau', 'Pemandangan sunrise, padang rumput', 3.5, 450, 'mudah'),\n",
        "        ('Gunung Merbabu', 'Sabana luas, sumber air di pos 2', 12.0, 1200, 'sulit'),\n",
        "        ('Gunung Sindoro', 'Jalur curam, hutan pinus', 8.0, 1400, 'sangat sulit'),\n",
        "        ('Bukit Sikunir', 'Jalur pendek sunrise', 1.5, 150, 'mudah'),\n",
        "        ('Gunung Sumbing', 'Trek panjang, kawah, air terjun', 10.0, 1800, 'sangat sulit'),\n",
        "    ]\n",
        "    for name, desc, dist, ele, diff in samples:\n",
        "        stats = {\n",
        "            'distance_km': dist, 'elevation_gain_m': ele,\n",
        "            'naismith_duration_hour': round((dist/5) + (ele/600), 2),\n",
        "            'average_grade_pct': round((ele/(dist*1000))*100, 2),\n",
        "            'min_elevation': 1500, 'max_elevation': 2500 + ele, 'difficulty': diff\n",
        "        }\n",
        "        narrative = generate_narrative(stats, desc)\n",
        "        routes_database.append({\n",
        "            'id': len(routes_database) + 1, 'name': name, 'stats': stats,\n",
        "            'narrative_text': narrative,\n",
        "            'embedding': generate_embedding(preprocess_text(narrative, False))\n",
        "        })\n",
        "        print(f\"âœ… {name}\")\n",
        "    print(f\"\\nðŸ“š {len(routes_database)} sample routes loaded\")"
      ],
      "metadata": {
        "id": "sample-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9ï¸âƒ£ Pencarian dengan Natural Language\n",
        "query = input(\"ðŸ” Masukkan preferensi (contoh: 'jalur mudah untuk pemula'): \")\n",
        "\n",
        "if query.strip():\n",
        "    results = search_routes(query, 5)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸ“Š HASIL REKOMENDASI\")\n",
        "    print(\"Formula: Sim(Q,D) = (QÂ·D) / (||Q||Ã—||D||)\")\n",
        "    print(\"=\"*60)\n",
        "    for i, r in enumerate(results, 1):\n",
        "        route = r['route']\n",
        "        print(f\"\\n#{i} {route['name']}\")\n",
        "        print(f\"   ðŸ“ {route['stats']['distance_km']}km | â›°ï¸ {route['stats']['elevation_gain_m']}m | ðŸ·ï¸ {route['stats']['difficulty']}\")\n",
        "        print(f\"   ðŸ“Š Similarity: {r['similarity']:.4f} ({r['similarity']*100:.1f}%)\")\n",
        "        print(f\"   ðŸ¤– {route['narrative_text'][:100]}...\")"
      ],
      "metadata": {
        "id": "search"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ”Ÿ Test Berbagai Query\n",
        "test_queries = [\n",
        "    \"jalur mudah untuk pemula\",\n",
        "    \"trek menantang elevasi tinggi\",\n",
        "    \"pendakian singkat 2-3 jam\",\n",
        "    \"jalur landai sabana sunrise\"\n",
        "]\n",
        "\n",
        "for q in test_queries:\n",
        "    print(f\"\\nðŸ” Query: '{q}'\")\n",
        "    for i, r in enumerate(search_routes(q, 3), 1):\n",
        "        print(f\"   {i}. {r['route']['name']} - {r['similarity']:.4f}\")"
      ],
      "metadata": {
        "id": "test-queries"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1ï¸âƒ£1ï¸âƒ£ Export ke CSV\n",
        "df = pd.DataFrame([{\n",
        "    'ID': r['id'], 'Nama': r['name'],\n",
        "    'Jarak_km': r['stats']['distance_km'],\n",
        "    'Elevasi_m': r['stats']['elevation_gain_m'],\n",
        "    'Durasi_jam': r['stats']['naismith_duration_hour'],\n",
        "    'Grade_%': r['stats']['average_grade_pct'],\n",
        "    'Kesulitan': r['stats']['difficulty'],\n",
        "    'Narrative': r['narrative_text']\n",
        "} for r in routes_database])\n",
        "\n",
        "df.to_csv('hiking_routes.csv', index=False)\n",
        "files.download('hiking_routes.csv')\n",
        "print(\"âœ… Exported!\")"
      ],
      "metadata": {
        "id": "export-csv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
